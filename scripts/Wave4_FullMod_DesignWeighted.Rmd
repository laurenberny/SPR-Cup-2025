---
title: "Design-Weighted"
author: "Waddling the Path"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(csSampling)
library(dplyr)
library(brms)
library(rstan)
library(survey)
library(cmdstanr)
library(tidyverse)
library(ggeffects)
library(lme4)
library(merTools)
library(labelled)
library(sjPlot)
library(Metrics)
library(janitor)
library(here)
library(rio)
```


# Load and Prepare Data

Must filer out any cases with missing weights, strata demos, and outcome.


```{r}

load(here("data", "combined_clean.RData"))

dat <- full %>% 
 mutate(across(region:age, as.factor)) %>%
 filter(wave==4) %>% 
 filter(!is.na(weight)) %>% 
 filter(!is.na(sex)) %>% 
 filter(!is.na(age)) %>% 
 filter(!is.na(eprod_edsd))

dat <- dat %>% 
  mutate(strata = 1000 * as.numeric(region) + 
                   100 * as.numeric(age) + 
                    10 * as.numeric(sex) + 
                     1 * as.numeric(race_ethnicity))

n_distinct(dat$strata)
```


# MAIHDA Prep

## Define priors

If we did not have any covariates (like in null model), you do not include the prior for beta.


```{r}
path_priors <- c(
  # logit scale
  prior(normal(0, 2), class = Intercept),
  prior(normal(0, 2), class = b),
  # variance component
  prior(inv_gamma(2, 2), class = sd))
```


## Survey rep object

```{r}
dat$wt_norm <- dat$weight*(length(dat$weight)/sum(dat$weight))

design_sp1 <- svrepdesign(
  data = dat,
  type = "Fay",
  rho = 0.3,
  repweights = dat[, grep("^rep_weight_[0-9]+$", names(dat))],
  weights = ~wt_norm,
  mse = TRUE)

# Check mean of weights from subpop survey design object
summary(design_sp1$pweights)
# Calibrate weights so the mean=1
design_sp1 <- calibrate(design_sp1,
                        ~ 1,
                        c(`(Intercept)` = length(design_sp1$pweights)),
                        compress = FALSE)
# Check mean after calibration
summary(design_sp1$pweights) # Mean=1
```


# MAIHDA

```{r}
# Write and save Stan file
stancode_pyMDE_m2 <- make_stancode(
  brmsformula(
    as.factor(eprod_edsd)| weights(wt_norm) ~ 
      1 + region + age + sex + race_ethnicity + (1 | strata)
    ), 
  data = dat,
  prior = path_priors,
  family = bernoulli(link="logit"),
  save_model = "brms_pyMDE_m2.stan")
# Load the Stan file
modbrms_pyMDE_m2 <- stan_model("brms_pyMDE_m2.stan")

# Set up data
databrms_pyMDE_m2 <- make_standata(
  brmsformula(
    as.factor(eprod_edsd)| weights(wt_norm) ~ 
      1 + region + age + sex + race_ethnicity + (1 | strata)
    ),
  data = design_sp1$variables,
  prior = path_priors,
  family = bernoulli(link="logit"))

# Set Stan model weights = survey design weights
databrms_pyMDE_m2$weights <- design_sp1$pweights


set.seed(828) # for reproducible results
pyMDE_m2 <- cs_sampling(
  svydes = design_sp1, # use the subpop-defined survey object
  mod_stan = modbrms_pyMDE_m2,
  data_stan = databrms_pyMDE_m2,
  ctrl_stan = list(chains = 4,
                   iter = 8000, # 16,000 total iterations (8,000 post-warmup)
                   warmup = 4000, # 8,000 warmups
                   prior = path_priors,
                   backend = "cmdstanr",
                   threads = threading(2),
                   thin = 1),
  rep_design = TRUE,
  sampling_args = list(cores = 4))

saveRDS(pyMDE_m2, file="wave4_fullmod.RDS")
```


```{r}
wave4_full <- readRDS(here("models", "Wave 4", "Weighted Bayesian", "wave4_fullmod.RDS"))

load(here("data", "combined_clean.RData"))
```


# Summaries

From depression paper.

```{r}
wave4_full <- wave4_full$stan_fit

## Extract parameter estimates, effective sample size (ESS), and r-hat 
## from each model fit. Specify 95% credible intervals.


wave4_full_sum = as.data.frame(rstan::summary(wave4_full,
                                probs = c(0.025, 0.975))$summary)

# histogram of r-hat values
bayesplot::mcmc_rhat_hist(wave4_full_sum$Rhat) +
  ggtitle("Histogram of model parameter r-hat values",
          "Full Model") +
  theme(axis.title = element_text(face="bold")) +
  labs(y="Frequency", x="r-hat values")

wave4_full_array <- as.array(wave4_full)
dimnames(wave4_full_array)[[3]][c(1:9, 11, 205)] <-
  c("region2", "region3", "region4",
    "age2", "age3", "female", 
    "race2", "race3", "race4",
    "Between-group std. dev.", "b_Intercept")

parameters <- dimnames(wave4_full_array)[[3]][c(1:9, 11, 205)]

# Autocorrelation plots
autocor_plots(array = wave4_full_array, 
              parsList = parameters)

# Trace plots for each parameter
trace_plots(array = wave4_full_array,
            parsList = parameters)


wave4_full_estimates <- wave4_full_sum %>% 
  # keep rows with beta coefficients
  # 10/24/2024 Note: We have updated this to the correct intercept parameter 
  # ("b_Intercept")
  filter(rownames(.) %in% c("b[1]", "b[2]", "b[3]", 
                            "b[4]", "b[5]", "b[6]",
                            "b[7]", "b[8]", "b[9]",
                            "b_Intercept")) %>% 
  mutate(
    parameter = c("region2",
                  "region3",
                  "region4",
                  "age2",
                  "age3",
                  "female",
                  "race2",
                  "race3",
                  "race4",
                  "Intercept"),
    OR = format(round(exp(mean),digits=2),nsmall=2),
    LB = format(round(exp(`2.5%`),digits=2),nsmall=2),
    UB = format(round(exp(`97.5%`),digits=2),nsmall=2),
    est = paste(OR," (",LB,", ",UB,")", sep=""))
 #  ) %>% 
 # dplyr::select(parameter, est)


```


# Post-Estimation Predictions


Note: From ChatGPT, sort of got overwhelmed by the depression tutorial. Probably should work on that, though, as I am not confident how correct this is


```{r}
# 1. Extract posterior draws from the stan_fit object

# Extract posterior draws
draws <- rstan::extract(wave4_full[["stan_fit"]])

# Key components
b_draws       <- draws[["b"]]           # [iterations x predictors]
b_Intercept   <- draws[["b_Intercept"]] # [iterations]
re_draws      <- draws[["r_1_1"]]       # [iterations x strata]


# 2. Create 1 row per strata with typical covariates

dat_wv4 <- full %>% 
 mutate(across(region:age, as.factor)) %>%
 filter(wave==4) %>% 
 filter(!is.na(weight)) %>% 
 filter(!is.na(sex)) %>% 
 filter(!is.na(age)) %>% 
 filter(!is.na(eprod_edsd))

dat_wv4 <- dat_wv4 %>% 
  mutate(strata = 1000 * as.numeric(region) + 
                   100 * as.numeric(age) + 
                    10 * as.numeric(sex) + 
                     1 * as.numeric(race_ethnicity))

newdata_strata <- dat_wv4 %>%
 dplyr::select(strata, region, age, sex, race_ethnicity) %>% 
 unique()

# 3. Create the design matrix X using the same formula

# Create model matrix WITHOUT intercept (b_Intercept handled separately)
X <- model.matrix(~ region + age + sex + race_ethnicity, data = newdata_strata)

X <- X[, 2:10]



# 4. Compute the predicted probabilities for each strata

n_iter <- nrow(b_draws)
n_strata <- nrow(X)

prob_matrix <- matrix(NA, nrow = n_iter, ncol = n_strata)

for (s in 1:n_strata) {
  x_stratum <- as.numeric(X[s, ])
  eta <- b_Intercept + as.vector(b_draws %*% x_stratum) + re_draws[, s]
  prob_matrix[, s] <- plogis(eta)
}



strata_preds <- data.frame(
  strata = newdata_strata$strata,
  Estimate = apply(prob_matrix, 2, mean),
  Q2.5     = apply(prob_matrix, 2, quantile, 0.025),
  Q97.5    = apply(prob_matrix, 2, quantile, 0.975)
)

```


Helpers from depression paper.


```{r}
# Autocorrelation plots
autocor_plots <- function(array, parsList) {
  lapply(parsList, function(x) {
    bayesplot::mcmc_acf(array, pars = x) +
      ggtitle(paste("Autocorrelation plots for", x)) +
      theme(axis.title = element_text(face = "bold"),
            text = element_text(family = "Arial"))
  })
}


# Trace plots
trace_plots <- function(array, parsList) {
  lapply(parsList, function(x) {
    bayesplot::mcmc_trace(array, pars = x) +
      ggtitle(paste("Trace plots for", x)) +
      theme(axis.title = element_text(face = "bold"),
            text = element_text(family = "Arial"))
  })
}

logit2prob <- function(logit) {
  odds = exp(logit)
  prob = odds / (1 + odds)
  return(prob)
}



```

